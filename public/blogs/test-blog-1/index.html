<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Research on Chest X-Rays | Rahul Goel</title>
<meta name=keywords content><meta name=description content="This research focuses on Multi-label classification of Chest X-ray images with the help of various Deep Learning models like DenseNet121, MobileNetV2, etc; to predict multiple lung diseases which include Emphysema, Hernia, Pneumonia, Cardiomegaly, and many more.
It also addresses the problem of Class Imbalance with the help of techniques like Undersampling and Oversampling in the dataset which itself is challenging as undersampling removes instances from the majority class, and oversampling adds copies of instances from the minority class to the dataset. Thus, the lack of a clear definition of minority and majority class instances prevents a straightforward application of these two methods. Paper"><meta name=author content><link rel=canonical href=http://localhost:1313/blogs/test-blog-1/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.6ae728cd5ea231ee259c6844266e72846b1c208c274868f760f2322a7857a66c.css integrity="sha256-aucozV6iMe4lnGhEJm5yhGscIIwnSGj3YPIyKnhXpmw=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/blogs/test-blog-1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/blogs/test-blog-1/"><meta property="og:site_name" content="Rahul Goel"><meta property="og:title" content="Research on Chest X-Rays"><meta property="og:description" content="This research focuses on Multi-label classification of Chest X-ray images with the help of various Deep Learning models like DenseNet121, MobileNetV2, etc; to predict multiple lung diseases which include Emphysema, Hernia, Pneumonia, Cardiomegaly, and many more.
It also addresses the problem of Class Imbalance with the help of techniques like Undersampling and Oversampling in the dataset which itself is challenging as undersampling removes instances from the majority class, and oversampling adds copies of instances from the minority class to the dataset. Thus, the lack of a clear definition of minority and majority class instances prevents a straightforward application of these two methods. Paper"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2025-02-13T23:15:00+07:00"><meta property="article:modified_time" content="2025-02-13T23:15:00+07:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Research on Chest X-Rays"><meta name=twitter:description content="This research focuses on Multi-label classification of Chest X-ray images with the help of various Deep Learning models like DenseNet121, MobileNetV2, etc; to predict multiple lung diseases which include Emphysema, Hernia, Pneumonia, Cardiomegaly, and many more.
It also addresses the problem of Class Imbalance with the help of techniques like Undersampling and Oversampling in the dataset which itself is challenging as undersampling removes instances from the majority class, and oversampling adds copies of instances from the minority class to the dataset. Thus, the lack of a clear definition of minority and majority class instances prevents a straightforward application of these two methods. Paper"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"http://localhost:1313/blogs/"},{"@type":"ListItem","position":2,"name":"Research on Chest X-Rays","item":"http://localhost:1313/blogs/test-blog-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Research on Chest X-Rays","name":"Research on Chest X-Rays","description":"This research focuses on Multi-label classification of Chest X-ray images with the help of various Deep Learning models like DenseNet121, MobileNetV2, etc; to predict multiple lung diseases which include Emphysema, Hernia, Pneumonia, Cardiomegaly, and many more.\nIt also addresses the problem of Class Imbalance with the help of techniques like Undersampling and Oversampling in the dataset which itself is challenging as undersampling removes instances from the majority class, and oversampling adds copies of instances from the minority class to the dataset. Thus, the lack of a clear definition of minority and majority class instances prevents a straightforward application of these two methods. Paper\n","keywords":[],"articleBody":"This research focuses on Multi-label classification of Chest X-ray images with the help of various Deep Learning models like DenseNet121, MobileNetV2, etc; to predict multiple lung diseases which include Emphysema, Hernia, Pneumonia, Cardiomegaly, and many more.\nIt also addresses the problem of Class Imbalance with the help of techniques like Undersampling and Oversampling in the dataset which itself is challenging as undersampling removes instances from the majority class, and oversampling adds copies of instances from the minority class to the dataset. Thus, the lack of a clear definition of minority and majority class instances prevents a straightforward application of these two methods. Paper\nAlso, CLAHE Enhancement is applied to reduce noise and improve image quality. Finally after training, DenseNet121 achieved the best performance among all the models evaluated using various metrics.\nDataset The ChestX-ray14 dataset is one of the largest collections of anterior-view pulmonary X-ray scan data. For this research, a total of 112,120 bilateral thoracic X-ray data were obtained from the dataset. The ChestX-ray14 dataset contains data of 14 disease classes and a no finding class from 30805 unique patients. These disease classes are Emphysema, Infiltration, Mass, Pleural Thickening, Pneumonia, Pneumothorax, Atelectasis, Edema, Effusion, Hernia, Cardiomegaly, Pulmonary Fibrosis, Nodule, and Consolidation. No finding means the 14 listed disease patterns are not found in the image.\nPreprocessing Steps The following steps were taken for preprocessing:\nCLAHE Enhancement Without CLAHE With CLAHE Contrast-limited adaptive histogram equalization (CLAHE) applied on all images to reduce noise and improving image quality. The tile size and clip limit are critical hyper-parameters for this method. An incorrect selection of hyper-parameters could have a big influence on the image quality. The optimal ones tileGridSize (10, 10) and the clip limit (3) were chosen here.\nData Balancing Before After As you can see in the above bar chart that the dataset is highly imbalanced as the No Finding class contains 60361 images which is about 53% of the whole dataset whereas Hernia contains only 227 images. And this imbalanced dataset further results in a high biased model predictions and poor performance for minority classes. So it is very important to first balance the dataset with the help of techniques like Undersampling and Oversampling to make it balanced then proceed for training.\nThe following steps were taken to balance the dataset:\nAs the dataset was highly imbalanced, an Undersampling technique was applied by Randomly Removing examples from over-represented classes to balance the dataset. This was done for each class individually, ensuring fairness in a multi-label setting.\nAfter undersampling , Oversampling of dataset was done by using Data Augmention with the help of Albumentations library to increase diversity. The following transformations were applied to the images:\nHorizontalFlip RandomRotate90 VerticalFlip Sharpen (with different probability of transform after each iteration) Finally, all images were resized to 224x224 pixels to ensure uniform input dimensions for the model, optimizing performance and compatibility with the chosen architecture.\nThese steps helped both balance the dataset and also resizing it for further training of our model.\nModel Training The model training was done on Kaggleâ€™s TPU VM v3-8 with 330GB of RAM.\nTrained several deep learning models with a 70:15:15 split as the train:validation:test set which includes:\nAlexNet DenseNet121 InceptionResNetv2 MobileNetV2 Used binary_crossentropy as a multi-label loss function, with sigmoid as activation and Adam as its optimizer.\nVarious Evaluation Metrics were calculated besides Accuracy and Loss to assess overall performance which includes:\nAUC F1-score Precision Recall Results Finally, after training, DenseNet121 achieved the best performance among all the models evaluated using various metrics.\nProblems When finalizing this work, I read this Kaggleâ€™s discussion which redirects to a Blog post by a radiologist stating that this dataset is in fact has some problems like:\nCompared to human visual assessment, the labels in the ChestXray14 dataset are inaccurate, unclear, and often describe medically unimportant findings.\nThese label problems are internally consistent within the data, meaning models can show good test-set performance, while still producing predictions that donâ€™t make medical sense.\nThe above combination of problems mean the dataset as defined currently is not fit for training medical systems, and research on the dataset cannot generate valid medical claims without significant additional justification.\nAcknowledgments I read several research papers to gain insights into different methodologies used in medical research involving deep learning:\nChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases, Xiaosong Wang et al High-precision multiclass classification of lung disease through customized MobileNetV2 from chest X-ray images, F.J.M. Shamrat et al SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models for Multi-Label Chest X-Ray Classification, S.M. Nabil Ashraf et al Automated Classification of Lung Cancer Subtypes Using Deep Learning and CT-Scan Based Radiomic Analysis, Bryce Dunn et al Improving Brain Tumor Classification: An Approach Integrating Pre-Trained CNN Models and Machine Learning Algorithm, M.R. Shoaib, J. Zhao, H.M. Emara et al Multi-Class Classification of Brain Disease using Machine Learning-Deep Learning approaches and Ranking based Similar Image Retrieval from Large Dataset, Dr. Dhanraj R.Dhotre et al LungNet22: A Fine-Tuned Model for Multiclass Classification and Prediction of Lung Disease Using X-ray Images, F. M. Javed Mehedi Shamrat et al Enhanced diagnostic accuracy for multiple lung diseases using a fine-tuned MobileNetV2 model with advanced pre-processing techniques, Deepak Thakur et al ","wordCount":"875","inLanguage":"en","datePublished":"2025-02-13T23:15:00+07:00","dateModified":"2025-02-13T23:15:00+07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/blogs/test-blog-1/"},"publisher":{"@type":"Organization","name":"Rahul Goel","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/><img src=http://localhost:1313/images/coding.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle y><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/blogs/ title=Blog><span>Blog</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Research on Chest X-Rays</h1><div class=post-meta><span title='2025-02-13 23:15:00 +0700 +0700'>February 13, 2025</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#dataset aria-label=Dataset>Dataset</a></li><li><a href=#preprocessing-steps aria-label="Preprocessing Steps">Preprocessing Steps</a><ul><li><a href=#clahe-enhancement aria-label="CLAHE Enhancement">CLAHE Enhancement</a></li><li><a href=#data-balancing aria-label="Data Balancing">Data Balancing</a></li></ul></li><li><a href=#model-training aria-label="Model Training">Model Training</a></li><li><a href=#results aria-label=Results>Results</a></li><li><a href=#problems aria-label=Problems>Problems</a></li><li><a href=#acknowledgments aria-label=Acknowledgments>Acknowledgments</a></li></ul></div></details></div><div class=post-content><p>This research focuses on <strong>Multi-label classification</strong> of Chest X-ray images with the help of various <strong>Deep Learning models</strong> like DenseNet121, MobileNetV2, etc; to predict multiple lung diseases which include Emphysema, Hernia, Pneumonia, Cardiomegaly, and many more.</p><p>It also addresses the problem of <strong>Class Imbalance</strong> with the help of techniques like <strong>Undersampling</strong> and <strong>Oversampling</strong> in the dataset which itself is <strong>challenging</strong> as undersampling removes instances from the majority class, and oversampling adds copies of instances from the minority class to the dataset. Thus, the lack of a clear definition of minority and majority class instances prevents a straightforward application of these two methods. <a href=https://www.sciencedirect.com/science/article/pii/S0950705124009894>Paper</a></p><p>Also, <strong>CLAHE Enhancement</strong> is applied to reduce noise and improve image quality. Finally after training, <code>DenseNet121</code> achieved the best performance among all the models evaluated using various metrics.</p><h2 id=dataset>Dataset<a hidden class=anchor aria-hidden=true href=#dataset>#</a></h2><p>The ChestX-ray14 dataset is <strong>one of the largest</strong> collections of anterior-view pulmonary X-ray scan data. For this research, a total of <strong>112,120</strong> bilateral thoracic X-ray data were obtained from the dataset. The ChestX-ray14 dataset contains data of <strong>14 disease classes</strong> and a <strong>no finding class</strong> from <strong>30805 unique patients</strong>. These disease classes are Emphysema, Infiltration, Mass, Pleural Thickening, Pneumonia, Pneumothorax, Atelectasis, Edema, Effusion, Hernia, Cardiomegaly, Pulmonary Fibrosis, Nodule, and Consolidation. <code>No finding</code> means the 14 listed disease patterns are not found in the image.</p><h2 id=preprocessing-steps>Preprocessing Steps<a hidden class=anchor aria-hidden=true href=#preprocessing-steps>#</a></h2><p>The following steps were taken for preprocessing:</p><h3 id=clahe-enhancement>CLAHE Enhancement<a hidden class=anchor aria-hidden=true href=#clahe-enhancement>#</a></h3><table><thead><tr><th>Without CLAHE</th><th>With CLAHE</th></tr></thead><tbody><tr><td><img loading=lazy src=https://github.com/user-attachments/assets/95d15c98-1185-44a0-b579-5b8c7aafaf02></td><td><img loading=lazy src=https://github.com/user-attachments/assets/3e6c2ad8-62fc-4887-ba3d-cfd830056343></td></tr></tbody></table><p>Contrast-limited adaptive histogram equalization (CLAHE) applied on all images to <strong>reduce noise</strong> and <strong>improving image quality</strong>. The tile size and clip limit are critical hyper-parameters for this method. An incorrect selection of hyper-parameters could have a big influence on the image quality. The optimal ones <code>tileGridSize (10, 10)</code> and the <code>clip limit (3)</code> were chosen here.</p><h3 id=data-balancing>Data Balancing<a hidden class=anchor aria-hidden=true href=#data-balancing>#</a></h3><table><thead><tr><th>Before</th><th>After</th></tr></thead><tbody><tr><td><img alt="before preprocessing" loading=lazy src=https://github.com/user-attachments/assets/0504325e-b125-4704-908b-e9cdf945dd6a></td><td><img alt="after preprocessing" loading=lazy src=https://github.com/user-attachments/assets/1eda7c99-6045-4d46-b8f3-69dc9bb491f5></td></tr></tbody></table><p>As you can see in the above bar chart that the dataset is highly imbalanced as the <code>No Finding</code> class contains 60361 images which is about <strong>53% of the whole dataset</strong> whereas <code>Hernia</code> contains only 227 images. And this imbalanced dataset further results in a high biased model predictions and poor performance for minority classes. So it is very important to first balance the dataset with the help of techniques like <strong>Undersampling</strong> and <strong>Oversampling</strong> to make it balanced then proceed for training.</p><p>The following steps were taken to balance the dataset:</p><ul><li><p>As the dataset was highly imbalanced, an <strong>Undersampling</strong> technique was applied by <strong>Randomly Removing</strong> examples from over-represented classes to balance the dataset. This was done for each class individually, ensuring fairness in a multi-label setting.</p></li><li><p>After undersampling , <strong>Oversampling</strong> of dataset was done by using <strong>Data Augmention</strong> with the help of <a href=https://github.com/albumentations-team/albumentations>Albumentations</a> library to increase diversity. The following transformations were applied to the images:</p><ul><li>HorizontalFlip</li><li>RandomRotate90</li><li>VerticalFlip</li><li>Sharpen (with different probability of transform after each iteration)</li></ul><p><img loading=lazy src=https://github.com/user-attachments/assets/c741c793-4ead-43f7-99ab-5e8ebd604fb2></p></li><li><p>Finally, all images were resized to <strong>224x224</strong> pixels to ensure uniform input dimensions for the model, optimizing performance and compatibility with the chosen architecture.</p></li></ul><p>These steps helped both balance the dataset and also resizing it for further training of our model.</p><h2 id=model-training>Model Training<a hidden class=anchor aria-hidden=true href=#model-training>#</a></h2><p>The model training was done on <strong>Kaggle&rsquo;s TPU VM v3-8</strong> with 330GB of RAM.</p><ul><li><p>Trained several deep learning models with a <code>70:15:15</code> split as the <code>train:validation:test</code> set which includes:</p><ul><li>AlexNet</li><li>DenseNet121</li><li>InceptionResNetv2</li><li>MobileNetV2</li></ul></li><li><p>Used <code>binary_crossentropy</code> as a multi-label loss function, with <code>sigmoid</code> as activation and <code>Adam</code> as its optimizer.</p></li><li><p>Various <strong>Evaluation Metrics</strong> were calculated besides <code>Accuracy</code> and <code>Loss</code> to assess overall performance which includes:</p><ul><li>AUC</li><li>F1-score</li><li>Precision</li><li>Recall</li></ul></li></ul><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><p>Finally, after training, <code>DenseNet121</code> achieved the <strong>best performance</strong> among all the models evaluated using various metrics.</p><h2 id=problems>Problems<a hidden class=anchor aria-hidden=true href=#problems>#</a></h2><p>When finalizing this work, I read this <a href=https://www.kaggle.com/datasets/nih-chest-xrays/data/discussion/300917>Kaggle&rsquo;s discussion</a> which redirects to a <a href=https://laurenoakdenrayner.com/2017/12/18/the-chestxray14-dataset-problems/>Blog post</a> by a radiologist stating that this dataset is in fact has some problems like:</p><ul><li><p>Compared to human visual assessment, the labels in the ChestXray14 dataset are inaccurate, unclear, and often describe medically unimportant findings.</p></li><li><p>These label problems are internally consistent within the data, meaning models can show good test-set performance, while still producing predictions that donâ€™t make medical sense.</p></li><li><p>The above combination of problems mean the dataset as defined currently is not fit for training medical systems, and research on the dataset cannot generate valid medical claims without significant additional justification.</p></li></ul><h2 id=acknowledgments>Acknowledgments<a hidden class=anchor aria-hidden=true href=#acknowledgments>#</a></h2><p>I read several research papers to gain insights into different methodologies used in medical research involving deep learning:</p><ul><li><a href=https://arxiv.org/abs/1705.02315>ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases, Xiaosong Wang et al</a></li><li><a href=https://www.sciencedirect.com/science/article/pii/S0010482523001117>High-precision multiclass classification of lung disease through customized MobileNetV2 from chest X-ray images, F.J.M. Shamrat et al</a></li><li><a href=https://arxiv.org/abs/2311.07750>SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models for Multi-Label Chest X-Ray Classification, S.M. Nabil Ashraf et al</a></li><li><a href=https://www.researchgate.net/publication/371388434_Automated_Classification_of_Lung_Cancer_Subtypes_Using_Deep_Learning_and_CT-Scan_Based_Radiomic_Analysis>Automated Classification of Lung Cancer Subtypes Using Deep Learning and CT-Scan Based Radiomic Analysis, Bryce Dunn et al</a></li><li><a href=https://www.sciencedirect.com/science/article/pii/S2405844024095021>Improving Brain Tumor Classification: An Approach Integrating Pre-Trained CNN Models and Machine Learning Algorithm, M.R. Shoaib, J. Zhao, H.M. Emara et al</a></li><li><a href=https://www.ijisae.org/index.php/IJISAE/article/view/3550>Multi-Class Classification of Brain Disease using Machine Learning-Deep Learning approaches and Ranking based Similar Image Retrieval from Large Dataset, Dr. Dhanraj R.Dhotre et al</a></li><li><a href=https://www.mdpi.com/2075-4426/12/5/680>LungNet22: A Fine-Tuned Model for Multiclass Classification and Prediction of Lung Disease Using X-ray Images, F. M. Javed Mehedi Shamrat et al</a></li><li><a href=https://www.sciencedirect.com/science/article/abs/pii/S0957417424021390>Enhanced diagnostic accuracy for multiple lung diseases using a fine-tuned MobileNetV2 model with advanced pre-processing techniques, Deepak Thakur et al</a></li></ul></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=http://localhost:1313/blogs/test-blog-2/><span class=title>Â« Prev</span><br><span>Making of an ANPR system</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Research on Chest X-Rays on x" href="https://x.com/intent/tweet/?text=Research%20on%20Chest%20X-Rays&amp;url=http%3a%2f%2flocalhost%3a1313%2fblogs%2ftest-blog-1%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Research on Chest X-Rays on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fblogs%2ftest-blog-1%2f&amp;title=Research%20on%20Chest%20X-Rays&amp;summary=Research%20on%20Chest%20X-Rays&amp;source=http%3a%2f%2flocalhost%3a1313%2fblogs%2ftest-blog-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Research on Chest X-Rays on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fblogs%2ftest-blog-1%2f&title=Research%20on%20Chest%20X-Rays"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Research on Chest X-Rays on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fblogs%2ftest-blog-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li></ul></footer></article></main><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>